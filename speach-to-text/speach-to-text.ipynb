{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from openai import OpenAI\n",
    "import tomllib as tl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the TOML file\n",
    "toml_file_path = '../secrets.toml'\n",
    "\n",
    "# Read the TOML file\n",
    "with open(toml_file_path, 'rb') as f:\n",
    "    toml_data = tl.load(f)\n",
    "\n",
    "api_key = toml_data['OPEN_AI_API_KEY']\n",
    "\n",
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are a text summariser. You will be given a text input and you need to summarise it.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berna\\AppData\\Local\\Temp\\ipykernel_28396\\690020612.py:81: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  chatbot = gr.Chatbot(label=\"Conversation\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7867\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7867/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Store conversation history\n",
    "chat_history = []\n",
    "\n",
    "def transcribe_audio(audio_file):\n",
    "    if not audio_file:\n",
    "        return \"No audio file provided.\"\n",
    "    try:\n",
    "        with open(audio_file, \"rb\") as audio:\n",
    "            transcription = client.audio.transcriptions.create(\n",
    "                model=\"whisper-1\",\n",
    "                file=audio\n",
    "            )\n",
    "        return transcription.text\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred during transcription: {str(e)}\"\n",
    "\n",
    "def chat_with_gpt(message, history):\n",
    "    \"\"\"Send the message to GPT and get a response\"\"\"\n",
    "    # Convert history to the format expected by OpenAI API\n",
    "    messages = []\n",
    "    for human, ai in history:\n",
    "        messages.append({\"role\": \"user\", \"content\": human})\n",
    "        messages.append({\"role\": \"assistant\", \"content\": ai})\n",
    "    \n",
    "    # Add the current message\n",
    "    messages.append({\"role\": \"user\", \"content\": message})\n",
    "    \n",
    "    try:\n",
    "        # Call the OpenAI API to get a response\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=messages\n",
    "        )\n",
    "        \n",
    "        # Return the assistant's response\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {str(e)}\"\n",
    "\n",
    "def process_audio_and_respond(audio_file, chat_history):\n",
    "    \"\"\"Process the audio file and respond using GPT\"\"\"\n",
    "    if not audio_file:\n",
    "        return chat_history + [[\"Please upload an audio file.\", \"I'm waiting for an audio file to transcribe.\"]]\n",
    "    \n",
    "    # Transcribe the audio\n",
    "    transcription = transcribe_audio(audio_file)\n",
    "    \n",
    "    # Add the transcription to the chat history as a user message\n",
    "    chat_history.append([f\"[Transcribed Audio]: {transcription}\", \"\"])\n",
    "    \n",
    "    # Get response from GPT\n",
    "    gpt_response = chat_with_gpt(transcription, chat_history[:-1])\n",
    "    \n",
    "    # Update the last assistant response\n",
    "    chat_history[-1][1] = gpt_response\n",
    "    \n",
    "    return chat_history\n",
    "\n",
    "def submit_text(text, chat_history):\n",
    "    \"\"\"Handle text input from the user\"\"\"\n",
    "    # Add the user message to history\n",
    "    chat_history.append([text, \"\"])\n",
    "    \n",
    "    # Get response from GPT\n",
    "    gpt_response = chat_with_gpt(text, chat_history[:-1])\n",
    "    \n",
    "    # Update the last assistant response\n",
    "    chat_history[-1][1] = gpt_response\n",
    "    \n",
    "    return \"\", chat_history  # Clear the text input and return updated history\n",
    "\n",
    "# Create the Gradio interface with both audio input and chat\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# Audio Transcription Chatbot\")\n",
    "    gr.Markdown(\"Upload an audio file to transcribe and discuss, or type your message directly.\")\n",
    "    \n",
    "    chatbot = gr.Chatbot(label=\"Conversation\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=4):\n",
    "            txt_input = gr.Textbox(\n",
    "                show_label=False,\n",
    "                placeholder=\"Type your message here...\",\n",
    "                container=False\n",
    "            )\n",
    "        with gr.Column(scale=1):\n",
    "            audio_input = gr.Audio(\n",
    "                type=\"filepath\",\n",
    "                label=\"Or upload audio\"\n",
    "            )\n",
    "    \n",
    "    # Setup event handlers\n",
    "    txt_input.submit(submit_text, [txt_input, chatbot], [txt_input, chatbot])\n",
    "    audio_input.change(process_audio_and_respond, [audio_input, chatbot], [chatbot])\n",
    "    \n",
    "    gr.Markdown(\"\"\"\n",
    "    ## How to use\n",
    "    1. Upload an audio file to transcribe it and start a conversation about its content\n",
    "    2. Or type a message directly to chat without audio\n",
    "    3. The chatbot will remember the conversation context\n",
    "    \"\"\")\n",
    "\n",
    "# Launch the app\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
